{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP-4740 Project 1: Convolutional Neural Network on MNIST Dataset\n",
    "Submitted by: Saffa Alvi, Nour ElKott <br>\n",
    "March 1, 2022 <br>\n",
    "\n",
    "This file contains the source code for our CNN architecture and \n",
    "shows the application of our model to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public API for tf.keras.datasets.mnist namespace - import TensorFlow and MNIST dataset under the Keras API\n",
    "mnist = tf.keras.datasets.mnist # 0-9, 28x28 images, 1 colour channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Separated as train and test, separates the labels/classes and the images.<br>\n",
    "X_train and X_test parts contain greyscale RGB codes (from 0 to 255).<br>\n",
    "Y_train and Y_test parts contain labels from 0 to 9 for the image number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  (60000, 28, 28)\n",
      "Test dataset size:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: \", X_train.shape)\n",
    "print(\"Test dataset size: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize dataset\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])     # display index 0 of training group as an image\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Normalize and Reshape the Datasets** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1) \n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)   \n",
    "\n",
    "# need to reshape the data as keras needs 4D datasets, and ours are 3D right now\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# new reshaped dataset\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Building the Model** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 21:36:46.821117: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dropout.Dropout at 0x7fa8be68c3d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model = tf.keras.models.Sequential() # most common model\n",
    "\n",
    "# add l2 regularization - not used \n",
    "# l2 = tf.keras.regularizers.l2(0.00015)\n",
    "\n",
    "# add the layers\n",
    "\n",
    "# hidden layers\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "# add dropout regularization\n",
    "tf.keras.layers.Dropout(0.30)\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256, (3,3), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "# add dropout regularization\n",
    "tf.keras.layers.Dropout(0.40)\n",
    "\n",
    "# flattens out the input layer\n",
    "model.add(tf.keras.layers.Flatten()) \n",
    "\n",
    "# output layer\n",
    "# last dense layer must have 10 neurons as we have 10 classes\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "# add dropout regularization\n",
    "tf.keras.layers.Dropout(0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and Fit the Model** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 73s 39ms/step - loss: 0.1146 - accuracy: 0.9646\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.0444 - accuracy: 0.9860\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 77s 41ms/step - loss: 0.0310 - accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa8c9abc5e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=3) # epoch is the number of passes through the entire training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Loss and Accuracy using Test Dataset** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0327 - accuracy: 0.9905\n",
      "0.03274731710553169 0.9904999732971191\n"
     ]
    }
   ],
   "source": [
    "# calculate validation loss and accuracy using the test dataset\n",
    "valLoss, valAcc = model.evaluate(X_test, Y_test)\n",
    "print(valLoss, valAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 128)       1280      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                64010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 360,458\n",
      "Trainable params: 360,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28, 1) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "[[1.7419692e-10 7.5373688e-14 4.6352636e-08 ... 1.0000000e+00\n",
      "  4.5959113e-12 5.3855648e-10]\n",
      " [2.7883198e-06 1.5533486e-07 9.9999440e-01 ... 6.3918293e-08\n",
      "  4.8302127e-07 1.2860167e-10]\n",
      " [1.9553241e-09 9.9997103e-01 5.9214109e-09 ... 1.8494620e-05\n",
      "  1.7250861e-06 1.8249558e-07]\n",
      " ...\n",
      " [1.9180741e-14 3.0649341e-10 1.4562883e-14 ... 2.4345326e-08\n",
      "  1.3495490e-07 5.2862902e-08]\n",
      " [1.0851271e-10 5.2889373e-16 2.6607657e-11 ... 1.0692882e-14\n",
      "  5.9764449e-07 3.7437529e-11]\n",
      " [2.3907159e-08 1.3756509e-12 1.8115630e-08 ... 4.6485368e-14\n",
      "  1.5944741e-09 1.0364394e-11]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([X_test])\n",
    "print(predictions) # prints the probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the handwritten digit and the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "w, x, y, z = X_test.shape\n",
    "\n",
    "while(1):\n",
    "    \n",
    "    # choose random sample from test dataset\n",
    "    num1 = random.randint(0, x)\n",
    "    \n",
    "    # show sample chosen\n",
    "    plt.imshow(X_test[num1])\n",
    "    plt.show()\n",
    "    \n",
    "    # show model prediction\n",
    "    print(\"Model Prediction: \", np.argmax(predictions[num1]))\n",
    "    \n",
    "    # Pause when 'q' is entered\n",
    "    cont = input('Paused - press ENTER to continue, q to exit: ')\n",
    "    if cont == 'q':\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
